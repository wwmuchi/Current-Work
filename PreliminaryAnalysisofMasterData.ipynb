{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filepath1 = 'Exports/Data/7.TractMasterDataset.csv'\n",
    "filepath2 ='Exports/Data/6.CountyMasterDataset.csv'\n",
    "\n",
    "tract_data = pd.read_csv(filepath1)\n",
    "county_data = pd.read_csv(filepath2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***County Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>SAMPLE</th>\n",
       "      <th>SERIAL</th>\n",
       "      <th>CBSERIAL</th>\n",
       "      <th>HHWT</th>\n",
       "      <th>CLUSTER</th>\n",
       "      <th>STATEFIP</th>\n",
       "      <th>COUNTYFIP</th>\n",
       "      <th>STRATA</th>\n",
       "      <th>GQ</th>\n",
       "      <th>...</th>\n",
       "      <th>STATEFP</th>\n",
       "      <th>COUNTYFP</th>\n",
       "      <th>weighted_ave_HH_conc</th>\n",
       "      <th>weighted_ave_non_HH_conc</th>\n",
       "      <th>weighted_sum_HH_conc</th>\n",
       "      <th>weighted_sum_non_HH_conc</th>\n",
       "      <th>non_weighted_ave_HH_conc</th>\n",
       "      <th>non_weighted_ave_non_HH_conc</th>\n",
       "      <th>non_weighted_sum_HH_conc</th>\n",
       "      <th>non_weighted_sum_non_HH_conc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>201001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2010000000021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>220001</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.205318</td>\n",
       "      <td>0.794682</td>\n",
       "      <td>2441.1</td>\n",
       "      <td>9448.275</td>\n",
       "      <td>0.205759</td>\n",
       "      <td>0.794241</td>\n",
       "      <td>343.0</td>\n",
       "      <td>1324.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>201001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2010000000021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>220001</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.205318</td>\n",
       "      <td>0.794682</td>\n",
       "      <td>2441.1</td>\n",
       "      <td>9448.275</td>\n",
       "      <td>0.205759</td>\n",
       "      <td>0.794241</td>\n",
       "      <td>343.0</td>\n",
       "      <td>1324.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>201001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2010000000021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>220001</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.205318</td>\n",
       "      <td>0.794682</td>\n",
       "      <td>2441.1</td>\n",
       "      <td>9448.275</td>\n",
       "      <td>0.205759</td>\n",
       "      <td>0.794241</td>\n",
       "      <td>343.0</td>\n",
       "      <td>1324.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>201001</td>\n",
       "      <td>4.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2010000000041</td>\n",
       "      <td>1.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>130001</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.075431</td>\n",
       "      <td>0.924569</td>\n",
       "      <td>35.0</td>\n",
       "      <td>429.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>201001</td>\n",
       "      <td>4.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2010000000041</td>\n",
       "      <td>1.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>130001</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.075431</td>\n",
       "      <td>0.924569</td>\n",
       "      <td>35.0</td>\n",
       "      <td>429.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR  SAMPLE  SERIAL  CBSERIAL  HHWT        CLUSTER  STATEFIP  COUNTYFIP  \\\n",
       "0  2010  201001     2.0      80.0  97.0  2010000000021       1.0       97.0   \n",
       "1  2010  201001     2.0      80.0  97.0  2010000000021       1.0       97.0   \n",
       "2  2010  201001     2.0      80.0  97.0  2010000000021       1.0       97.0   \n",
       "3  2010  201001     4.0     224.0  82.0  2010000000041       1.0      117.0   \n",
       "4  2010  201001     4.0     224.0  82.0  2010000000041       1.0      117.0   \n",
       "\n",
       "   STRATA  GQ  ...  STATEFP  COUNTYFP  weighted_ave_HH_conc  \\\n",
       "0  220001   1  ...      1.0      97.0              0.205318   \n",
       "1  220001   1  ...      1.0      97.0              0.205318   \n",
       "2  220001   1  ...      1.0      97.0              0.205318   \n",
       "3  130001   1  ...      1.0     117.0                   NaN   \n",
       "4  130001   1  ...      1.0     117.0                   NaN   \n",
       "\n",
       "   weighted_ave_non_HH_conc  weighted_sum_HH_conc  weighted_sum_non_HH_conc  \\\n",
       "0                  0.794682                2441.1                  9448.275   \n",
       "1                  0.794682                2441.1                  9448.275   \n",
       "2                  0.794682                2441.1                  9448.275   \n",
       "3                       NaN                   NaN                       NaN   \n",
       "4                       NaN                   NaN                       NaN   \n",
       "\n",
       "   non_weighted_ave_HH_conc  non_weighted_ave_non_HH_conc  \\\n",
       "0                  0.205759                      0.794241   \n",
       "1                  0.205759                      0.794241   \n",
       "2                  0.205759                      0.794241   \n",
       "3                  0.075431                      0.924569   \n",
       "4                  0.075431                      0.924569   \n",
       "\n",
       "   non_weighted_sum_HH_conc  non_weighted_sum_non_HH_conc  \n",
       "0                     343.0                        1324.0  \n",
       "1                     343.0                        1324.0  \n",
       "2                     343.0                        1324.0  \n",
       "3                      35.0                         429.0  \n",
       "4                      35.0                         429.0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "county_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Share of individuals living in birth state: 53.34%\n",
      "dropping...\n"
     ]
    }
   ],
   "source": [
    "# Restrict data to rows where BPL == STATEFP\n",
    "mask = county_data['BPL'] == county_data['STATEFP']\n",
    "print(f'Share of individuals living in birth state: {mask.mean():.2%}')\n",
    "print('dropping...')\n",
    "county_data = county_data[mask].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2010 is 13 years after 1997. Music influences people from the age of 10-17. So I will restrict sample to people aged 23-30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_data.query(\" 23 <= AGE <= 30\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Regressing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.84% of rows have missing rating data\n",
      "['non_weighted_ave_HH_conc', 'non_weighted_ave_non_HH_conc', 'non_weighted_sum_HH_conc', 'non_weighted_sum_non_HH_conc']\n"
     ]
    }
   ],
   "source": [
    "print(f'{county_data['weighted_ave_HH_conc'].isna().mean():.2%} of rows have missing rating data')\n",
    "hip_hop_cols = [col for col in county_data.columns if 'HH_conc' in col and 'non_weighted' in col]\n",
    "print(hip_hop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_and_control_cols = [\n",
    "    'SEX', 'AGE', 'MARST', 'RACE', 'HISPAN',\n",
    "    'EDUC', 'EMPSTAT',\n",
    "    'INCTOT'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows dropped: 2.76%\n"
     ]
    }
   ],
   "source": [
    "# Select only the necessary columns: dependent_var, control_cols, and hip_hop_var\n",
    "hip_hop_var = 'non_weighted_ave_HH_conc'\n",
    "required_cols = outcome_and_control_cols + [hip_hop_var] + ['STATEFP','COUNTYFP']\n",
    "print(f'rows dropped: {county_data[required_cols].isna().any(axis=1).mean():.2%}')\n",
    "data_subset = county_data[required_cols].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>MARST</th>\n",
       "      <th>RACE</th>\n",
       "      <th>HISPAN</th>\n",
       "      <th>EDUC</th>\n",
       "      <th>EMPSTAT</th>\n",
       "      <th>INCTOT</th>\n",
       "      <th>non_weighted_ave_HH_conc</th>\n",
       "      <th>STATEFP</th>\n",
       "      <th>COUNTYFP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>13000.0</td>\n",
       "      <td>0.205759</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>0.075431</td>\n",
       "      <td>1.0</td>\n",
       "      <td>117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>34000.0</td>\n",
       "      <td>0.086671</td>\n",
       "      <td>1.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>0.086671</td>\n",
       "      <td>1.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SEX   AGE  MARST  RACE  HISPAN  EDUC  EMPSTAT   INCTOT  \\\n",
       "1     2  26.0      1   1.0       0     7        1  13000.0   \n",
       "4     2  29.0      1   1.0       0     7        1  45000.0   \n",
       "34    2  27.0      6   1.0       0     6        3   2500.0   \n",
       "35    2  26.0      6   2.0       0    10        1  34000.0   \n",
       "36    1  27.0      6   2.0       0    10        1  40000.0   \n",
       "\n",
       "    non_weighted_ave_HH_conc  STATEFP  COUNTYFP  \n",
       "1                   0.205759      1.0      97.0  \n",
       "4                   0.075431      1.0     117.0  \n",
       "34                  0.000000      1.0      55.0  \n",
       "35                  0.086671      1.0      73.0  \n",
       "36                  0.086671      1.0      73.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_subset1 = data_subset.copy()\n",
    "data_subset1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>MARST</th>\n",
       "      <th>RACE</th>\n",
       "      <th>HISPAN</th>\n",
       "      <th>EDUC</th>\n",
       "      <th>EMPSTAT</th>\n",
       "      <th>INCTOT</th>\n",
       "      <th>non_weighted_ave_HH_conc</th>\n",
       "      <th>clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>13000.0</td>\n",
       "      <td>0.421994</td>\n",
       "      <td>100097.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>0.154703</td>\n",
       "      <td>100117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100055.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>34000.0</td>\n",
       "      <td>0.177755</td>\n",
       "      <td>100073.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>0.177755</td>\n",
       "      <td>100073.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SEX   AGE  MARST  RACE  HISPAN  EDUC  EMPSTAT   INCTOT  \\\n",
       "1     2  26.0      1   1.0       0     7        1  13000.0   \n",
       "4     2  29.0      1   1.0       0     7        1  45000.0   \n",
       "34    2  27.0      6   1.0       0     6        3   2500.0   \n",
       "35    2  26.0      6   2.0       0    10        1  34000.0   \n",
       "36    1  27.0      6   2.0       0    10        1  40000.0   \n",
       "\n",
       "    non_weighted_ave_HH_conc  clusters  \n",
       "1                   0.421994  100097.0  \n",
       "4                   0.154703  100117.0  \n",
       "34                  0.000000  100055.0  \n",
       "35                  0.177755  100073.0  \n",
       "36                  0.177755  100073.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_value = data_subset1[hip_hop_var].min()\n",
    "max_value = data_subset1[hip_hop_var].max()\n",
    "data_subset1[hip_hop_var] = (data_subset1[hip_hop_var] - min_value) / (max_value - min_value)\n",
    "\n",
    "# Cluster identifiers\n",
    "data_subset1['clusters'] = data_subset1['STATEFP'] * 1e5 + data_subset1['COUNTYFP']\n",
    "data_subset1.drop(columns=['STATEFP', 'COUNTYFP'], inplace=True)\n",
    "\n",
    "\n",
    "data_subset1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_subset1.groupby('clusters').size().value_counts().hist()\n",
    "plt.xlabel('Cluster Size (Distribution of Observations per County)')\n",
    "plt.ylabel('Frequency (Number of Counties)')\n",
    "plt.title('Number of Observations per County')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subset1.drop(columns=['clusters'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# dependent_var_options = [('EDUC', 6), ('INCTOT', None), ('MARST', 4), ('MARST', 6), ('EMPSTAT', 2)]\n",
    "dependent_var_options = [('INCTOT', None)]\n",
    "\n",
    "\n",
    "# Iterate through dependent variables and outcomes\n",
    "for dependent_var, dependent_var_outcome in dependent_var_options:\n",
    "    print(f\"Dependent variable: {dependent_var}\")\n",
    "\n",
    "    # Iterate through unique RACE values\n",
    "    for race_value in [1,2]:\n",
    "        print(f\"RACE: {race_value}\")\n",
    "\n",
    "        # Filter data for the current RACE group\n",
    "        data_subset = data_subset1[data_subset1['RACE'] == race_value].copy()\n",
    "\n",
    "        control_cols = [col for col in outcome_and_control_cols if col != dependent_var]\n",
    "\n",
    "        # Convert dependent variable into a binary variable\n",
    "        if dependent_var == 'EDUC':\n",
    "            data_subset[dependent_var] = (data_subset[dependent_var] < dependent_var_outcome).astype(int)\n",
    "        elif dependent_var_outcome is not None:\n",
    "            data_subset[dependent_var] = (data_subset[dependent_var] == dependent_var_outcome).astype(int)\n",
    "        else:\n",
    "            data_subset[dependent_var] = data_subset[dependent_var].astype(int)\n",
    "\n",
    "        for col in data_subset.columns:\n",
    "            if col not in [dependent_var, 'AGE', 'clusters', 'RACE'] and (\n",
    "                data_subset[col].dtype == 'object' or data_subset[col].nunique() < 10\n",
    "            ):  # Categorical criteria\n",
    "                dummies = pd.get_dummies(data_subset[col], prefix=col, drop_first=True)\n",
    "                data_subset = pd.concat([data_subset.drop(columns=[col]), dummies], axis=1)\n",
    "\n",
    "        # Separate dependent and independent variables\n",
    "        y = data_subset[dependent_var]\n",
    "        X_all = sm.add_constant(data_subset.drop(columns=[dependent_var, 'RACE']))  # All potential independent variables\n",
    "        assert X_all.shape[0] == y.shape[0]\n",
    "        assert not X_all.isna().any().any()\n",
    "        assert not y.isna().any()\n",
    "        X_all = X_all.astype(float)\n",
    "\n",
    "        # Initialize a dictionary to store regression results\n",
    "        regression_results = {}\n",
    "\n",
    "        independent_vars = [hip_hop_var] + [col for col in X_all.columns if col not in hip_hop_cols]\n",
    "        X = X_all[independent_vars]  # Subset only relevant columns\n",
    "\n",
    "        # Perform the regression\n",
    "        model = sm.OLS(y, X)\n",
    "        results = model.fit()\n",
    "\n",
    "        # Store the results in the dictionary\n",
    "        regression_results[(dependent_var, race_value, hip_hop_var)] = results\n",
    "\n",
    "        # Print summary for each regression\n",
    "        print(f\"Regression for dependent variable {dependent_var}, independent variable {hip_hop_var}, and RACE: {race_value}:\")\n",
    "        print(results.summary())\n",
    "        print(\"\\n\" + \"=\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract results into a DataFrame\n",
    "coefficients = results.params\n",
    "p_values = results.pvalues\n",
    "summary_df = pd.DataFrame({\n",
    "    'Coefficient': coefficients,\n",
    "    'P-Value': p_values\n",
    "})\n",
    "\n",
    "# Sort or group by variable types\n",
    "summary_df = summary_df.sort_index()\n",
    "\n",
    "# Define the mapping dictionaries\n",
    "mapping = {\n",
    "    'SEX_1': 'Male',\n",
    "    'SEX_2': 'Female',\n",
    "    'EMPSTAT_2.0': 'Unemployed',\n",
    "    'EMPSTAT_3.0': 'Not in labor force',\n",
    "    'HISPAN_1.0': 'Mexican',\n",
    "    'HISPAN_2.0': 'Puerto Rican',\n",
    "    'HISPAN_3.0': 'Cuban',\n",
    "    'HISPAN_4.0': 'Other Hispanic',\n",
    "    'MARST_2.0': 'Married, spouse absent',\n",
    "    'MARST_3.0': 'Separated',\n",
    "    'MARST_4.0': 'Divorced',\n",
    "    'MARST_5.0': 'Widowed',\n",
    "    'MARST_6.0': 'Never married/single',\n",
    "    'RACE_2.0': 'Black/African American',\n",
    "    'RACE_3.0': 'American Indian or Alaska Native',\n",
    "    'RACE_4.0': 'Chinese',\n",
    "    'RACE_5.0': 'Japanese',\n",
    "    'RACE_6.0': 'Other Asian or Pacific Islander',\n",
    "    'RACE_7.0': 'Other race, nec',\n",
    "    'RACE_8.0': 'Two major races',\n",
    "    'const': 'Intercept',\n",
    "    'INCTOT': 'Total Personal Income',\n",
    "    'non_weighted_ave_HH_conc': 'Hip Hop Exposure During Adolescence',\n",
    "    'AGE': 'Age',\n",
    "    # Add age mappings for clarity (AGE_24.0 -> Age 24, etc.)\n",
    "    **{f'AGE_{i}.0': f'Age {i}' for i in range(24, 31)}\n",
    "}\n",
    "\n",
    "# Update indices in summary_df\n",
    "summary_df = summary_df.rename(index=mapping)\n",
    "\n",
    "summary_df['P-Value'] = summary_df['P-Value'].map(lambda p: f'{p:.4f}')\n",
    "summary_df['Coefficient'] = summary_df['Coefficient'].map(lambda c: f'{c:.4f}')\n",
    "\n",
    "summary_df.reset_index(inplace=True)\n",
    "summary_df.rename(columns={'index': 'Variable'}, inplace=True)\n",
    "\n",
    "summary_df.sort_values('P-Value', inplace=True)\n",
    "\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reset index to make 'Coefficient' a column\n",
    "summary_df_reset = summary_df.reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "summary_df_reset.rename(columns={'index': 'Variable'}, inplace=True)\n",
    "\n",
    "# Plot all coefficients\n",
    "plt.figure(figsize=(10, 8))\n",
    "summary_df_reset.set_index('Variable')['Coefficient'].plot(\n",
    "    kind='bar', \n",
    "    color='skyblue', \n",
    "    yerr=summary_df_reset['P-Value'],  # Use P-Value or Std Err for error bars if applicable\n",
    "    capsize=4\n",
    ")\n",
    "plt.title('Effect of Independent Variables on High School Graduation')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.xlabel('Variables')\n",
    "plt.axhline(0, color='red', linestyle='--', linewidth=1)\n",
    "plt.xticks(rotation=90)  # Rotate x-axis labels for better visibility\n",
    "plt.tight_layout()  # Adjust layout to prevent clipping\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant = summary_df[summary_df['P-Value'] < 0.05]\n",
    "print(\"Significant Variables:\\n\", significant)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "station_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
